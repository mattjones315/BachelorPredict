{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import numba\n",
    "from numba import jit\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from chainer.datasets import TupleDataset\n",
    "from chainer.dataset import DatasetMixin\n",
    "import pandas as pd \n",
    "import PIL \n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.cuda import to_cpu\n",
    "\n",
    "from chainer import cuda, Chain\n",
    "from chainer import optimizers\n",
    "from chainer import serializers\n",
    "from chainer import links, functions, Variable\n",
    "\n",
    "from scipy import ndimage, misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def source_image_data(data_file, label_col, image_col, remove_nas): \n",
    "    \n",
    "    if remove_nas:\n",
    "        data_file = data_file.dropna(subset=[image_col, label_col])  # remove missing data for now \n",
    "    \n",
    "    image_list = data_file[image_col].tolist()\n",
    "    label_list = data_file.index\n",
    "    \n",
    "    return image_list, label_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_greyscale(fp, new_path, imname):\n",
    "    \"\"\"Converts an image to greyscale\"\"\"\n",
    "    img = Image.open(fp).convert('L')\n",
    "    np = new_path + imname\n",
    "    img.save(np)\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_iamge(fp):\n",
    "    \n",
    "    image = ndimage.imread(fp, mode=\"L\")\n",
    "    image_resized = misc.imresize(image, (112, 112))\n",
    "    return image_resized\n",
    "\n",
    "def get_image(image_path):\n",
    "    \"\"\"Get a numpy array of an image so that one can access values[x][y].\"\"\"\n",
    "    image = Image.open(image_path, 'r')\n",
    "    print(image.size)\n",
    "    width, height = image.size\n",
    "    pixel_values = list(image.getdata())\n",
    "    if image.mode == 'RGB':\n",
    "        channels = 3\n",
    "    elif image.mode == 'L':\n",
    "        channels = 1\n",
    "    else:\n",
    "        print(\"Unknown mode: %s\" % image.mode)\n",
    "        return None\n",
    "    pixel_values = np.array(pixel_values).reshape(width, height, channels)\n",
    "    return pixel_values\n",
    "\n",
    "def load_images(path_name, image_list): \n",
    "    \n",
    "    imlist = []\n",
    "    for i in image_list:\n",
    "        #fp = path_name + i\n",
    "        fp = convert_to_greyscale(path_name + i, \"images/\", \"grey_\" + i)\n",
    "        image = ndimage.imread(fp, mode = \"L\")\n",
    "        image_resized = misc.imresize(image, (128, 128, 3))\n",
    "#         image_resized = np.expand_dims(image_resized, axis=0)\n",
    "        prep_image = chainer.links.model.vision.vgg.prepare(image_resized)\n",
    "        imlist.append(prep_image)\n",
    "        \n",
    "    return imlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_for_chainer(images, labels): \n",
    "\n",
    "    return TupleDataset(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 50)\n",
      "(451, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ElimWeek</th>\n",
       "      <th>Employment.full.time</th>\n",
       "      <th>Employment.part.time</th>\n",
       "      <th>Employment.student</th>\n",
       "      <th>Employment.unemployed</th>\n",
       "      <th>Education.Needed.college</th>\n",
       "      <th>Education.Needed.high.school</th>\n",
       "      <th>Education.Needed.post.college</th>\n",
       "      <th>Region.west</th>\n",
       "      <th>Region.midwest</th>\n",
       "      <th>...</th>\n",
       "      <th>hair_wavy.straight.medium</th>\n",
       "      <th>hair_wavy.medium</th>\n",
       "      <th>hair_wavy.curly</th>\n",
       "      <th>hair_wavy.curly.medium</th>\n",
       "      <th>hair_length.chest</th>\n",
       "      <th>hair_length.shoulder</th>\n",
       "      <th>hair_length.stomach</th>\n",
       "      <th>hair_length.neck</th>\n",
       "      <th>hair_length.medium.dark</th>\n",
       "      <th>hair_length.short</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alexa</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amanda Marsh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amber</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amy</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angela</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ElimWeek  Employment.full.time  Employment.part.time  \\\n",
       "Name                                                                 \n",
       "Alexa              2.0                     1                     0   \n",
       "Amanda Marsh       NaN                     0                     1   \n",
       "Amber              1.0                     1                     0   \n",
       "Amy                2.0                     1                     0   \n",
       "Angela             2.0                     0                     1   \n",
       "\n",
       "              Employment.student  Employment.unemployed  \\\n",
       "Name                                                      \n",
       "Alexa                          0                      0   \n",
       "Amanda Marsh                   0                      0   \n",
       "Amber                          0                      0   \n",
       "Amy                            0                      0   \n",
       "Angela                         0                      0   \n",
       "\n",
       "              Education.Needed.college  Education.Needed.high.school  \\\n",
       "Name                                                                   \n",
       "Alexa                                1                             0   \n",
       "Amanda Marsh                         1                             0   \n",
       "Amber                                1                             0   \n",
       "Amy                                  0                             1   \n",
       "Angela                               0                             1   \n",
       "\n",
       "              Education.Needed.post.college  Region.west  Region.midwest  \\\n",
       "Name                                                                       \n",
       "Alexa                                     0            1               0   \n",
       "Amanda Marsh                              0            0               1   \n",
       "Amber                                     0            1               0   \n",
       "Amy                                       0            1               0   \n",
       "Angela                                    0            1               0   \n",
       "\n",
       "                    ...          hair_wavy.straight.medium  hair_wavy.medium  \\\n",
       "Name                ...                                                        \n",
       "Alexa               ...                                NaN               NaN   \n",
       "Amanda Marsh        ...                                NaN               NaN   \n",
       "Amber               ...                                NaN               NaN   \n",
       "Amy                 ...                                NaN               NaN   \n",
       "Angela              ...                                NaN               NaN   \n",
       "\n",
       "              hair_wavy.curly  hair_wavy.curly.medium  hair_length.chest  \\\n",
       "Name                                                                       \n",
       "Alexa                     NaN                     NaN                NaN   \n",
       "Amanda Marsh              NaN                     NaN                NaN   \n",
       "Amber                     NaN                     NaN                NaN   \n",
       "Amy                       NaN                     NaN                NaN   \n",
       "Angela                    NaN                     NaN                NaN   \n",
       "\n",
       "              hair_length.shoulder  hair_length.stomach  hair_length.neck  \\\n",
       "Name                                                                        \n",
       "Alexa                          NaN                  NaN               NaN   \n",
       "Amanda Marsh                   NaN                  NaN               NaN   \n",
       "Amber                          NaN                  NaN               NaN   \n",
       "Amy                            NaN                  NaN               NaN   \n",
       "Angela                         NaN                  NaN               NaN   \n",
       "\n",
       "              hair_length.medium.dark  hair_length.short  \n",
       "Name                                                      \n",
       "Alexa                             NaN                NaN  \n",
       "Amanda Marsh                      NaN                NaN  \n",
       "Amber                             NaN                NaN  \n",
       "Amy                               NaN                NaN  \n",
       "Angela                            NaN                NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enc = pd.read_csv(\"/home/ccaggian/BachelorPredict/encoded.csv\")\n",
    "df_all = pd.read_csv(\"/home/ccaggian/BachelorPredict/one_hot_encoded.csv\")\n",
    "df_all.index = df_all[\"Name\"]\n",
    "df_enc.index = df_all[\"Name\"]\n",
    "df_enc = df_enc.drop(columns = [\"Season\", \"intro_order\"])\n",
    "df_enc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Height</th>\n",
       "      <th>ElimWeek</th>\n",
       "      <th>Season</th>\n",
       "      <th>hair_wavy</th>\n",
       "      <th>hometown_name</th>\n",
       "      <th>height_inches</th>\n",
       "      <th>...</th>\n",
       "      <th>photo_url</th>\n",
       "      <th>hometown_state</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>goneweek</th>\n",
       "      <th>featured</th>\n",
       "      <th>featured_num</th>\n",
       "      <th>intro_order</th>\n",
       "      <th>hometown_pop_2010</th>\n",
       "      <th>hometown_pop_2013</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Vienna Girardi</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Marketing Representative</td>\n",
       "      <td>Geneva, Florida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vienna_Bachelor_14.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Wendi</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Technology Specialist</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Whitney</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Pilates Instructor</td>\n",
       "      <td>Chanhassen, MN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whitney_Bachelor_21.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Whitney Bischoff</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Fertility Nurse</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2698000.0</td>\n",
       "      <td>2719000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Nicole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight-medium</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://static.east.abc.go.com/service/image/ra...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>caucasian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>217558.0</td>\n",
       "      <td>226918.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name   Age                Occupation              Hometown  \\\n",
       "419    Vienna Girardi  23.0  Marketing Representative       Geneva, Florida   \n",
       "420             Wendi  26.0     Technology Specialist         Dallas, Texas   \n",
       "421           Whitney  25.0        Pilates Instructor        Chanhassen, MN   \n",
       "422  Whitney Bischoff  29.0           Fertility Nurse  Louisville, Kentucky   \n",
       "423            Nicole   NaN                       NaN                   NaN   \n",
       "\n",
       "     Height  ElimWeek  Season        hair_wavy hometown_name  height_inches  \\\n",
       "419     NaN       NaN    14.0              NaN           NaN            NaN   \n",
       "420     NaN       1.0     1.0              NaN           NaN            NaN   \n",
       "421    68.0       6.0    21.0              NaN           NaN            NaN   \n",
       "422     NaN       NaN    19.0           medium       Chicago           67.0   \n",
       "423     NaN       NaN     NaN  straight-medium    Scottsdale           68.0   \n",
       "\n",
       "              ...             \\\n",
       "419           ...              \n",
       "420           ...              \n",
       "421           ...              \n",
       "422           ...              \n",
       "423           ...              \n",
       "\n",
       "                                             photo_url hometown_state  \\\n",
       "419                                                NaN            NaN   \n",
       "420                                                NaN            NaN   \n",
       "421                                                NaN            NaN   \n",
       "422                                                NaN             IL   \n",
       "423  http://static.east.abc.go.com/service/image/ra...             AZ   \n",
       "\n",
       "     ethnicity goneweek featured featured_num intro_order hometown_pop_2010  \\\n",
       "419        NaN      NaN      NaN          NaN         NaN               NaN   \n",
       "420        NaN      NaN      NaN          NaN         NaN               NaN   \n",
       "421        NaN      NaN      NaN          NaN         NaN               NaN   \n",
       "422  caucasian      NaN     True          4.0         2.0         2698000.0   \n",
       "423  caucasian      1.0      NaN          NaN        23.0          217558.0   \n",
       "\n",
       "    hometown_pop_2013                    image  \n",
       "419               NaN   Vienna_Bachelor_14.jpg  \n",
       "420               NaN                      NaN  \n",
       "421               NaN  Whitney_Bachelor_21.jpg  \n",
       "422         2719000.0                      NaN  \n",
       "423          226918.0                      NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_id = -1\n",
    "\n",
    "# hardcoded garbage that gets the csv and the appropriate labels/image data \n",
    "data_file = pd.read_csv(\"/home/ccaggian/bachelor_data/bachelor_females_images.csv\") \n",
    "image_folder_path = \"/home/ccaggian/bachelor_data/images/\"\n",
    "\n",
    "label_col = \"ElimWeek\"  # column with labels (week eliminated)\n",
    "image_col = \"image\"  # column with data (jpegs)\n",
    "\n",
    "images, labels = source_image_data(data_file, label_col, image_col, True)  # get appropriate data in list for chainer, remove nans\n",
    "\n",
    "images = load_images(image_folder_path, images)  # give appropriate absolute path of image data \n",
    "\n",
    "train_data = format_for_chainer(images, labels)\n",
    "\n",
    "data_file.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_ch, pool_drop=False):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(ConvBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv=L.Convolution2D(None, n_ch, 3, 1, 1, nobias=True, initialW=w)\n",
    "            self.bn=L.BatchNormalization(n_ch)\n",
    "        \n",
    "        self.pool_drop = pool_drop\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.bn(self.conv(x)))\n",
    "        if self.pool_drop:\n",
    "            h = F.max_pooling_2d(h, 2, 2)\n",
    "            h = F.dropout(h, ratio=0.25)\n",
    "        return h\n",
    "    \n",
    "class LinearBlock(chainer.Chain):\n",
    "    \n",
    "    def __init__(self):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(LinearBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.fc=L.Linear(None, 1024, initialW=w)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return F.dropout(F.relu(self.fc(x)), ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepCNN(chainer.ChainList):\n",
    "\n",
    "    def __init__(self, n_output):\n",
    "        super(DeepCNN, self).__init__(\n",
    "            ConvBlock(64),\n",
    "            ConvBlock(64, True),\n",
    "            ConvBlock(128),\n",
    "            ConvBlock(128, True),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256, True),\n",
    "            LinearBlock(),\n",
    "            LinearBlock(),\n",
    "            L.Linear(None, n_output)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        for f in self.children():\n",
    "            x = f(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG(Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.base = L.VGG16Layers()  \n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # refer to https://github.com/chainer/chainer/blob/master/chainer/links/model/vision/vgg.py for \n",
    "        # all possilbe layers to extract.\n",
    "        h = self.base (x, layers = [\"fc7\"])[\"fc7\"]\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = L.Classifier(DeepCNN(1))\n",
    "    \n",
    "# Setup an optimizer\n",
    "# optimizer = chainer.optimizers.SGD()\n",
    "# optimizer.setup(model)\n",
    "    \n",
    "# LOAD OUR DATASET HERE INSTEAD OF MNIST\n",
    "# test_iter = chainer.iterators.SerialIterator(test, batch_size=100, repeat=False, shuffle=False)\n",
    "    \n",
    "# Set up a trainer\n",
    "# updater = training.StandardUpdater(train_iter, optimizer, device=-1)\n",
    "# trainer = training.Trainer(updater, (5, 'epoch'), out='result')\n",
    "    \n",
    "# trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "# trainer.extend(extensions.LogReport())\n",
    "# trainer.extend(extensions.PrintReport( ['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy']))\n",
    "#trainer.extend(extensions.ProgressBar())\n",
    "# trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "# trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "    \n",
    "# Run the training\n",
    "#trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5984: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4120,)\n"
     ]
    }
   ],
   "source": [
    "# Section to create a fully connected input layer from images and extra variables\n",
    "\n",
    "model = VGG()\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(train_data, batch_size=1, shuffle=False)\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "\n",
    "for t in train_data:\n",
    "    \n",
    "    image_train, target_train = concat_examples([t], -1)\n",
    "    proc = model(image_train)\n",
    "    r = df_enc.iloc[target_train[0]]\n",
    "    \n",
    "    # Target is week eliminated\n",
    "    target = r[\"ElimWeek\"]\n",
    "    \n",
    "    # if NAN it means we didn't have data - setting to -1 to not cause an error\n",
    "    r[np.isnan(r)] = -1\n",
    "    \n",
    "    # add extra variables to output of image net\n",
    "    proc = np.append(proc, r[1:])\n",
    "    features.append(proc)\n",
    "    targets.append(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
