{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import numba\n",
    "from numba import jit\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from chainer.datasets import TupleDataset\n",
    "from chainer.dataset import DatasetMixin\n",
    "import pandas as pd \n",
    "import PIL \n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.cuda import to_cpu\n",
    "\n",
    "from chainer import cuda, Chain\n",
    "from chainer import optimizers\n",
    "from chainer import serializers\n",
    "from chainer import links, functions, Variable\n",
    "\n",
    "from scipy import ndimage, misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_image_data(data_file, label_col, image_col, remove_nas): \n",
    "    \n",
    "    if remove_nas:\n",
    "        data_file = data_file.dropna(subset=[image_col, label_col])  # remove missing data for now \n",
    "    \n",
    "    image_list = data_file[image_col].tolist()\n",
    "    label_list = data_file[label_col].tolist()\n",
    "    \n",
    "    return image_list, label_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_greyscale(fp, new_path, imname):\n",
    "    \"\"\"Converts an image to greyscale\"\"\"\n",
    "    img = Image.open(fp).convert('L')\n",
    "    np = new_path + imname\n",
    "    img.save(np)\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_iamge(fp):\n",
    "    \n",
    "    image = ndimage.imread(fp, mode=\"L\")\n",
    "    image_resized = misc.imresize(image, (112, 112))\n",
    "    return image_resized\n",
    "\n",
    "def get_image(image_path):\n",
    "    \"\"\"Get a numpy array of an image so that one can access values[x][y].\"\"\"\n",
    "    image = Image.open(image_path, 'r')\n",
    "    print(image.size)\n",
    "    width, height = image.size\n",
    "    pixel_values = list(image.getdata())\n",
    "    if image.mode == 'RGB':\n",
    "        channels = 3\n",
    "    elif image.mode == 'L':\n",
    "        channels = 1\n",
    "    else:\n",
    "        print(\"Unknown mode: %s\" % image.mode)\n",
    "        return None\n",
    "    pixel_values = np.array(pixel_values).reshape(width, height, channels)\n",
    "    return pixel_values\n",
    "\n",
    "def load_images(path_name, image_list): \n",
    "    \n",
    "    imlist = []\n",
    "    for i in image_list:\n",
    "        #fp = path_name + i\n",
    "        fp = convert_to_greyscale(path_name + i, \"images/\", \"grey_\" + i)\n",
    "        image = ndimage.imread(fp, mode = \"L\")\n",
    "        image_resized = misc.imresize(image, (128, 128, 3))\n",
    "#         image_resized = np.expand_dims(image_resized, axis=0)\n",
    "        prep_image = chainer.links.model.vision.vgg.prepare(image_resized)\n",
    "        imlist.append(prep_image)\n",
    "        \n",
    "    return imlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_chainer(images, labels): \n",
    "\n",
    "    return TupleDataset(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<chainer.datasets.tuple_dataset.TupleDataset at 0x7f17b24153c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_id = -1\n",
    "\n",
    "# hardcoded garbage that gets the csv and the appropriate labels/image data \n",
    "data_file = pd.read_csv(\"/home/ccaggian/bachelor_data/bachelor_females_images.csv\") \n",
    "image_folder_path = \"/home/ccaggian/bachelor_data/images/\"\n",
    "\n",
    "label_col = \"ElimWeek\"  # column with labels (week eliminated)\n",
    "image_col = \"image\"  # column with data (jpegs)\n",
    "\n",
    "images, labels = source_image_data(data_file, label_col, image_col, True)  # get appropriate data in list for chainer, remove nans\n",
    "\n",
    "images = load_images(image_folder_path, images)  # give appropriate absolute path of image data \n",
    "\n",
    "train_data = format_for_chainer(images, labels)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_ch, pool_drop=False):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(ConvBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv=L.Convolution2D(None, n_ch, 3, 1, 1, nobias=True, initialW=w)\n",
    "            self.bn=L.BatchNormalization(n_ch)\n",
    "        \n",
    "        self.pool_drop = pool_drop\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.bn(self.conv(x)))\n",
    "        if self.pool_drop:\n",
    "            h = F.max_pooling_2d(h, 2, 2)\n",
    "            h = F.dropout(h, ratio=0.25)\n",
    "        return h\n",
    "    \n",
    "class LinearBlock(chainer.Chain):\n",
    "    \n",
    "    def __init__(self):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(LinearBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.fc=L.Linear(None, 1024, initialW=w)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return F.dropout(F.relu(self.fc(x)), ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(chainer.ChainList):\n",
    "\n",
    "    def __init__(self, n_output):\n",
    "        super(DeepCNN, self).__init__(\n",
    "            ConvBlock(64),\n",
    "            ConvBlock(64, True),\n",
    "            ConvBlock(128),\n",
    "            ConvBlock(128, True),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256, True),\n",
    "            LinearBlock(),\n",
    "            LinearBlock(),\n",
    "            L.Linear(None, n_output)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        for f in self.children():\n",
    "            x = f(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.base = L.VGG16Layers()  \n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = self.base (x, layers = [\"fc7\"])[\"fc7\"]\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = L.Classifier(DeepCNN(1))\n",
    "    \n",
    "# Setup an optimizer\n",
    "# optimizer = chainer.optimizers.SGD()\n",
    "# optimizer.setup(model)\n",
    "    \n",
    "# LOAD OUR DATASET HERE INSTEAD OF MNIST\n",
    "# test_iter = chainer.iterators.SerialIterator(test, batch_size=100, repeat=False, shuffle=False)\n",
    "    \n",
    "# Set up a trainer\n",
    "# updater = training.StandardUpdater(train_iter, optimizer, device=-1)\n",
    "# trainer = training.Trainer(updater, (5, 'epoch'), out='result')\n",
    "    \n",
    "# trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "# trainer.extend(extensions.LogReport())\n",
    "# trainer.extend(extensions.PrintReport( ['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy']))\n",
    "#trainer.extend(extensions.ProgressBar())\n",
    "# trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "# trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "    \n",
    "# Run the training\n",
    "#trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.]\n"
     ]
    }
   ],
   "source": [
    "model = VGG()\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(train_data, batch_size=1)\n",
    "\n",
    "labs = []\n",
    "features = []\n",
    "\n",
    "train_batch = train_iter.next()\n",
    "image_train, target_train = concat_examples(train_batch, -1)\n",
    "prediction_train = model(image_train)\n",
    "\n",
    "has_next = True\n",
    "while has_next:\n",
    "    \n",
    "    try:\n",
    "        train_batch = train_iter.next()\n",
    "        image_train, target_train = concat_example(train_batch, -1)\n",
    "        proc = model(image_train)\n",
    "        labs.append(target_train[0])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
